# -*- coding: utf-8 -*-
"""Bank_Customer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o6gvbxazeTESfMIndccXfxx6NiUrC-tC
"""

import pandas as pd
import numpy as np
import seaborn as sns

df=pd.read_csv('/content/Bank Customer Churn Prediction.csv')

df.info()

df.shape

df.drop(['customer_id'],axis=1,inplace=True)

df

#check duplicates
#check for number of countries

from sklearn.preprocessing import LabelEncoder

df['country']=LabelEncoder().fit_transform(df['country'])

df['gender']=LabelEncoder().fit_transform(df['gender'])

df

#to check what does 0,1,2,3 means in converted categorical variable
df['country'].value_counts()

#in industry target variable is represented by y and feature variable is represented by X
X=df.drop(['churn'], axis=1)

y=df['churn']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=23)

X_train.shape

#to convert all variables into one score so we'll convert it into z score or convert it into normalised vvalue(0 and 1)
from sklearn.preprocessing import StandardScaler

std=StandardScaler()

X_train=std.fit_transform(X_train)
X_test=std.transform(X_test)

from sklearn.linear_model import LogisticRegression

cls=LogisticRegression()

cls.fit(X_train, y_train)

cls.score(X_train, y_train)

new_customer_data_dict={
    'credit_score':[2],
    'country' :[1],
    'gender':[0],
    'age':[40],
    'tenure':[2],
    'balance':[20700.00],
    'products_number':[3],
    'credit_card':[2],
    'active_member':[1],
    'estimated_salary':[100000.00]
}

new_customer_data = pd.DataFrame(new_customer_data_dict)

new_customer_data = new_customer_data[X.columns]

new_customer_data

scaled_data= std.transform(new_customer_data)

churn_prediction= cls.predict(scaled_data)

churn_prediction

from sklearn.metrics import confusion_matrix

y_predicted= cls.predict(X_test)

confusion_matrix(y_test, y_predicted)

reliability= cls.score(X_test, y_test)

reliability

from sklearn.model_selection import cross_val_score
cross_validation_score= cross_val_score(cls, X_train, y_train, cv=10)

cross_validation_score.mean()

f1_score= cross_val_score(cls, X_train, y_train, cv=10, scoring='f1')

f1_score.mean()

precision_score= cross_val_score(cls, X_train, y_train, cv=10, scoring='precision')

precision_score.mean()

import pickle

pickle.dump(cls,open('cls.sav','wb'))

